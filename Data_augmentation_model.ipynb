{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15229f7-7661-4a51-a3a1-c79c93a54765",
   "metadata": {
    "id": "168YUOMq-SrL"
   },
   "source": [
    "# **Art Classifier**\n",
    "\n",
    "## **Non Structured Data**\n",
    "\n",
    "This project has been done by:\n",
    "\n",
    "|Name                    |Email                              |\n",
    "|------------------------|-----------------------------------|\n",
    "|Jorge Ayuso Martínez    |jorgeayusomartinez@alu.comillas.edu|\n",
    "|Carlota Monedero Herranz|carlotamoh@alu.comillas.edu        |\n",
    "|José Manuel Vega Gradit |josemanuel.vega@alu.comillas.edu   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ebd7e6-de01-4dd2-a211-099e327856c2",
   "metadata": {
    "id": "3w6rBQM0_o7T"
   },
   "source": [
    "First of all, let's load the required libraries in order to run the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56148681-04e5-4f5c-8865-a7cfaaea8bca",
   "metadata": {
    "id": "Rh87ovI1-TCv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57621d-c6e3-489f-88ba-d5543ed70490",
   "metadata": {
    "id": "D8x-hAiaAblq"
   },
   "source": [
    "Now let's see how our data is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558b466-0276-47fa-820e-9b723fa381ea",
   "metadata": {
    "id": "pIfrW7zx-TEX"
   },
   "outputs": [],
   "source": [
    "# Root folder\n",
    "base_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622e546-7d82-4a94-a6dd-545a29235884",
   "metadata": {
    "id": "4A14qVrGMomZ"
   },
   "outputs": [],
   "source": [
    "# Train folder\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "\n",
    "# Validation folder\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "# Test folder\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe7c45c-b715-4217-b48b-97343c0f53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.walk(base_dir):\n",
    "    for folder in path[1]:\n",
    "        if \".ipynb_checkpoints\" in folder:\n",
    "            os.rmdir(os.path.join(path[0], folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258082b-1c56-445c-a355-13a882a48c6a",
   "metadata": {
    "id": "FWvgTz7ejmF0"
   },
   "source": [
    "Let's also see how many images there are for each class in the training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906904f6-fe43-4c22-92b9-e68621589e67",
   "metadata": {
    "id": "oGDiubz2jmOT"
   },
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "n_classes = len(os.listdir(train_dir))\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# Get existing classes\n",
    "classes = os.listdir(train_dir)\n",
    "print(\"Existing classes:\\n\")\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e6464-a5c6-4dd5-89b1-3ec9601b8a3a",
   "metadata": {
    "id": "fmhnayouqYQl"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "print(\"Number of images per class in Training set:\")\n",
    "print(\"=\"*50)\n",
    "for cl in classes:\n",
    "    n_images = len(os.listdir(os.path.join(train_dir, cl)))\n",
    "    print(f\"{cl}: {n_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b52947-e881-418a-9309-62c95848cdef",
   "metadata": {
    "id": "_nBKldzsrTm1"
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "print(\"Number of images per class in Validation set:\")\n",
    "print(\"=\"*50)\n",
    "for cl in classes:\n",
    "    n_images = len(os.listdir(os.path.join(validation_dir, cl)))\n",
    "    print(f\"{cl}: {n_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a82de-e8ac-47c9-98d6-c67987cc805d",
   "metadata": {
    "id": "8aFWVYRKrTzw"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "print(\"Number of images per class in Test set:\")\n",
    "print(\"=\"*50)\n",
    "for cl in classes:\n",
    "    n_images = len(os.listdir(os.path.join(test_dir, cl)))\n",
    "    print(f\"{cl}: {n_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd88db-6761-445f-a33e-f60c9bf3e63b",
   "metadata": {},
   "source": [
    "We'll also create the directory, if not created yet, where the models will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10f504-b5ba-4e94-90d9-f6cc863a1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory where to save the models created\n",
    "models_dir = \"./models\"\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b50e9-e7b3-41d7-b646-7405621431f2",
   "metadata": {
    "id": "lR3pXpNODl6O",
    "tags": []
   },
   "source": [
    "## **3. Model with dropout and data augmentation**\n",
    "\n",
    "*Explain dropout and data augmentation, include reference to original paper*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1584f-a8b2-4da6-bd86-f0969351a13e",
   "metadata": {
    "id": "ksRFFq2-WgBw"
   },
   "source": [
    "### 1.1. Model structure\n",
    "\n",
    "Let's first create the model structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ad3d9-5b0e-4098-bdda-5a53fd355c69",
   "metadata": {},
   "source": [
    "Firstly, let's define the values of some hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79ca96-a8b4-47ab-854a-ac04f9da50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some hyperparameters' values\n",
    "\n",
    "# Input shape\n",
    "input_shape = (128, 128,  3)\n",
    "\n",
    "# Batch_size and steps per epoch\n",
    "training_size = sum([len(file) for path, folder, file in os.walk(train_dir)])\n",
    "batch_size = 64\n",
    "steps_per_epoch = training_size // batch_size\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf3f8c-271d-4fea-8a4c-e2ad9137b2a5",
   "metadata": {
    "id": "35S_bt4t-TIX"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# 1st Convolution Layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=input_shape\n",
    "                        )\n",
    ")\n",
    "# 1st Pooling Layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# 2nd Convolution Layer\n",
    "model.add(layers.Conv2D(64, \n",
    "                        (3, 3), \n",
    "                        activation='relu'\n",
    "                       )\n",
    "         )\n",
    "# 2nd Pooling Layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# 3rd Convolution Layer\n",
    "model.add(layers.Conv2D(128, \n",
    "                        (3, 3), \n",
    "                        activation='relu'\n",
    "                        )\n",
    ")\n",
    "# 3rd Pooling Layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# 4th Convolution Layer\n",
    "model.add(layers.Conv2D(128, \n",
    "                        (3, 3), \n",
    "                        activation='relu'\n",
    "                        )\n",
    ")\n",
    "# 4th Pooling Layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97baed2-fd95-40b0-af7b-64946377cc76",
   "metadata": {
    "id": "R9Juyt3rLCKk"
   },
   "source": [
    "Once the structure of the base model has been defined, let's see exactly how many parameters it has in order to have a better idea of how flexible this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886fd9f-20a3-4e37-9f37-dd0f70b39707",
   "metadata": {
    "id": "Zqn2mE-n-TKl"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07be938-fc08-49cd-9bf3-f2856aa8013b",
   "metadata": {
    "id": "DB3cPq2nLVaR"
   },
   "source": [
    "We'll use Adam as our optimizer since it is the most popular optimizer right now, as well as versatile (i.e., it can be used in multiple contexts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73ae3a-6296-4aa5-bc43-a9988a33b39c",
   "metadata": {
    "id": "-PG_KXks-TMm"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2b842-77e7-40d5-93c9-40eadf68d664",
   "metadata": {
    "id": "q3I-ZQfNMUej"
   },
   "source": [
    "### 1.2. Data preprocessing\n",
    "\n",
    "In this case, we will include the Data Augmentation step to the model preprocessing step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fdbe7-8ccf-4408-a334-9f6607d80997",
   "metadata": {
    "id": "rF9cfUPS-TO1"
   },
   "outputs": [],
   "source": [
    "# Apply data augmentation to the training set\n",
    "# https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    # shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=(0.6, 1),\n",
    "    zoom_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "# The data augmentation must not be used for the test set!\n",
    "# All images will be rescaled by 1./255\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        # All images will be resized to the dimensions specified\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "        )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        # All images will be resized to the dimensions specified\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f44ef6-7ecb-42a1-9a14-6c5c56ba440a",
   "metadata": {
    "id": "3y0iM-VXQovT"
   },
   "source": [
    "Now let's take a look at the output of one of these generators (for instance, the training one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca1dc2-110f-4297-b605-2008fda45781",
   "metadata": {
    "id": "1Jf4AvO_-TRW"
   },
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300204f0-2752-4a20-aebe-53edd5229816",
   "metadata": {
    "id": "C7W1pa92Q3MK"
   },
   "source": [
    "*We can appreciate that...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94a8f7-399d-4d1a-971e-a1e949a3073a",
   "metadata": {
    "id": "ZoO2Da0IR51Y"
   },
   "source": [
    "### 1.3. Training\n",
    "\n",
    "Let's train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d312a3-85da-493e-8d34-177c9b8436be",
   "metadata": {},
   "source": [
    "We use [Early Stopping](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) to avoid *overfitting*, as well `ModelCheckpoint` to save the best model obtained during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb2bfb-f5a6-420e-b116-08c2b75bed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name and path\n",
    "model_path = os.path.join(\"models\", \"augmentation_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92816f76-414e-421e-9065-9248b20cd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(model_path, monitor='val_loss', \n",
    "                     mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a895e76-e3be-4158-b61d-7f6af5b99901",
   "metadata": {
    "id": "wrYxrr1OQ6qH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10,\n",
    "    callbacks = [es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0f815-2f2f-45b1-93c3-5c4120ac9a66",
   "metadata": {},
   "source": [
    "Now let's load the best model found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f7580-54fa-441f-8a5a-041e3ba84462",
   "metadata": {
    "id": "R6ScrxYY-TTQ"
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "saved_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac2e2c-b0fc-49ed-b23d-f3a2439a71bb",
   "metadata": {
    "id": "JWuATgMUS8bI"
   },
   "source": [
    "### 1.4. Validation\n",
    "\n",
    "Let's plot how the loss and the accuracy from both training and validations sets have evolved during the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb50f3d-f9db-4fa8-b395-b9c5337dbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eef723-37b8-452f-9675-2b640325e316",
   "metadata": {
    "id": "kXvSCIRP-TVZ"
   },
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "plt.figure(figsize=(15,10), dpi=200)\n",
    "\n",
    "plt.plot(epochs, acc, 'royalblue', linewidth=2, label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'blueviolet', linewidth=2, label='Validation acc')\n",
    "plt.title('Training and validation accuracy', fontsize=20)\n",
    "plt.legend(frameon=False, fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,10), dpi=200)\n",
    "\n",
    "plt.plot(epochs, loss, 'royalblue', linewidth=2, label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'blueviolet', linewidth=2, label='Validation loss')\n",
    "plt.title('Training and validation loss', fontsize=20)\n",
    "plt.legend(frameon=False, fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d735f4-0de1-4d11-9761-bb812d5cbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=40,\n",
    "        class_mode='categorical'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a15d3d-33f0-4f65-871d-bb7048c39494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3f158-c176-4111-b66e-45918c845472",
   "metadata": {
    "id": "pQg4z_l8Tbj9"
   },
   "source": [
    "*Comments about how those metrics have evolved...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
