{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f15229f7-7661-4a51-a3a1-c79c93a54765",
   "metadata": {
    "id": "168YUOMq-SrL"
   },
   "source": [
    "# **5. MobileNetV3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ebd7e6-de01-4dd2-a211-099e327856c2",
   "metadata": {
    "id": "3w6rBQM0_o7T"
   },
   "source": [
    "First of all, let's load the required libraries in order to run the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56148681-04e5-4f5c-8865-a7cfaaea8bca",
   "metadata": {
    "id": "Rh87ovI1-TCv"
   },
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import os\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow import debugging as tfdbg\n",
    "from tensorflow import device\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ResNet50\n",
    "from tensorflow.keras.applications import MobileNetV3Large, MobileNetV3Small\n",
    "\n",
    "# Own modules\n",
    "from src.utils import drop_checkpoints, dataset_stats, plot_metric_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57621d-c6e3-489f-88ba-d5543ed70490",
   "metadata": {
    "id": "D8x-hAiaAblq"
   },
   "source": [
    "Now let's see how our data is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7558b466-0276-47fa-820e-9b723fa381ea",
   "metadata": {
    "id": "pIfrW7zx-TEX"
   },
   "outputs": [],
   "source": [
    "# Root folder\n",
    "base_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7622e546-7d82-4a94-a6dd-545a29235884",
   "metadata": {
    "id": "4A14qVrGMomZ"
   },
   "outputs": [],
   "source": [
    "# Train folder\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "\n",
    "# Validation folder\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "# Test folder\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe7c45c-b715-4217-b48b-97343c0f53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_checkpoints(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258082b-1c56-445c-a355-13a882a48c6a",
   "metadata": {
    "id": "FWvgTz7ejmF0"
   },
   "source": [
    "Let's also see how many images there are for each class in the training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf7d899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4\n",
      "Existing classes: ['Baroque', 'Realism', 'Renaissance', 'Romanticism']\n",
      "\n",
      "----------------------------------------\n",
      "Number of images per class and dataset:\n",
      "----------------------------------------\n",
      "             Train  Validation  Test\n",
      "Style                               \n",
      "Baroque       4000         500   500\n",
      "Realism       4000         500   500\n",
      "Renaissance   4000         500   500\n",
      "Romanticism   4000         500   500\n"
     ]
    }
   ],
   "source": [
    "dataset_stats(train_dir, validation_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd88db-6761-445f-a33e-f60c9bf3e63b",
   "metadata": {},
   "source": [
    "We'll also create the directory, if not created yet, where the models will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f10f504-b5ba-4e94-90d9-f6cc863a1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory where to save the models created\n",
    "models_dir = \"./models\"\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b50e9-e7b3-41d7-b646-7405621431f2",
   "metadata": {
    "id": "lR3pXpNODl6O",
    "tags": []
   },
   "source": [
    "*Explain dropout and data augmentation, include reference to original paper*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "110dead2",
   "metadata": {},
   "source": [
    "# **5.1 MobileNetV3 with frozen convolutional base (just training classifier)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27d1584f-a8b2-4da6-bd86-f0969351a13e",
   "metadata": {
    "id": "ksRFFq2-WgBw"
   },
   "source": [
    "## 5.1.1. Model structure\n",
    "\n",
    "Let's first create the model structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ad3d9-5b0e-4098-bdda-5a53fd355c69",
   "metadata": {},
   "source": [
    "Firstly, let's define the values of some hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e79ca96-a8b4-47ab-854a-ac04f9da50df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 125\n"
     ]
    }
   ],
   "source": [
    "# Define some hyperparameters' values\n",
    "\n",
    "# Input shape\n",
    "input_shape = (224, 224,  3)\n",
    "\n",
    "# Batch_size and steps per epoch\n",
    "training_size = sum([len(file) for path, folder, file in os.walk(train_dir)])\n",
    "batch_size = 128\n",
    "steps_per_epoch = training_size // batch_size\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b5973c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base = MobileNetV3Large( \n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_shape=input_shape,\n",
    "#     alpha=1.0,\n",
    "#     pooling=None,\n",
    "#     dropout_rate=0.2,\n",
    "# )\n",
    "\n",
    "conv_base = MobileNetV3Small( \n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the convolutional base\n",
    "model.add(conv_base)\n",
    "\n",
    "# Add the classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Freeze the convolutional base\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97baed2-fd95-40b0-af7b-64946377cc76",
   "metadata": {
    "id": "R9Juyt3rLCKk"
   },
   "source": [
    "Once the structure of the base model has been defined, let's see exactly how many parameters it has in order to have a better idea of how flexible this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7886fd9f-20a3-4e37-9f37-dd0f70b39707",
   "metadata": {
    "id": "Zqn2mE-n-TKl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 28224)             0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 28224)            112896    \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               3612800   \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,673,844\n",
      "Trainable params: 3,678,020\n",
      "Non-trainable params: 995,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07be938-fc08-49cd-9bf3-f2856aa8013b",
   "metadata": {
    "id": "DB3cPq2nLVaR"
   },
   "source": [
    "We'll use Adam as our optimizer since it is the most popular optimizer right now, as well as versatile (i.e., it can be used in multiple contexts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c73ae3a-6296-4aa5-bc43-a9988a33b39c",
   "metadata": {
    "id": "-PG_KXks-TMm"
   },
   "outputs": [],
   "source": [
    "# optimizer = optimizers.SGD(learning_rate=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ead2b842-77e7-40d5-93c9-40eadf68d664",
   "metadata": {
    "id": "q3I-ZQfNMUej"
   },
   "source": [
    "## 5.1.2. Data preprocessing\n",
    "\n",
    "In this case, we will include the Data Augmentation step to the model preprocessing step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "998fdbe7-8ccf-4408-a334-9f6607d80997",
   "metadata": {
    "id": "rF9cfUPS-TO1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 4 classes.\n",
      "Found 2000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Apply data augmentation to the training set\n",
    "# https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.8, 1),\n",
    "    zoom_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "# The data augmentation must not be used for the test set!\n",
    "# All images will be rescaled by 1./255\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        # All images will be resized to the dimensions specified\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        # All images will be resized to the dimensions specified\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f44ef6-7ecb-42a1-9a14-6c5c56ba440a",
   "metadata": {
    "id": "3y0iM-VXQovT"
   },
   "source": [
    "Now let's take a look at the output of one of these generators (for instance, the training one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8ca1dc2-110f-4297-b605-2008fda45781",
   "metadata": {
    "id": "1Jf4AvO_-TRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: (128, 224, 224, 3)\n",
      "Labels batch shape: (128, 4)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data batch shape:', data_batch.shape)\n",
    "    print('Labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300204f0-2752-4a20-aebe-53edd5229816",
   "metadata": {
    "id": "C7W1pa92Q3MK"
   },
   "source": [
    "*We can appreciate that...*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e94a8f7-399d-4d1a-971e-a1e949a3073a",
   "metadata": {
    "id": "ZoO2Da0IR51Y"
   },
   "source": [
    "## 5.1.3. Training\n",
    "\n",
    "Let's train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d312a3-85da-493e-8d34-177c9b8436be",
   "metadata": {},
   "source": [
    "We use [Early Stopping](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) to avoid *overfitting*, as well `ModelCheckpoint` to save the best model obtained during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0cb2bfb-f5a6-420e-b116-08c2b75bed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name and path\n",
    "model_path = os.path.join(\"models\", \"mobile_frozen_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92816f76-414e-421e-9065-9248b20cd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(model_path, monitor='val_loss', \n",
    "                     mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a895e76-e3be-4158-b61d-7f6af5b99901",
   "metadata": {
    "id": "wrYxrr1OQ6qH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  4/125 [..............................] - ETA: 11:59 - loss: 3.0733 - acc: 0.2930"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     train_generator,\n\u001b[0;32m      3\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      7\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m     callbacks \u001b[39m=\u001b[39;49m [es, mc]\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10,\n",
    "    callbacks = [es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0f815-2f2f-45b1-93c3-5c4120ac9a66",
   "metadata": {},
   "source": [
    "Now let's load the best model found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2f7580-54fa-441f-8a5a-041e3ba84462",
   "metadata": {
    "id": "R6ScrxYY-TTQ"
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "saved_model = load_model(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44ac2e2c-b0fc-49ed-b23d-f3a2439a71bb",
   "metadata": {
    "id": "JWuATgMUS8bI"
   },
   "source": [
    "## 5.1.4. Validation\n",
    "\n",
    "Let's plot how the loss and the accuracy from both training and validations sets have evolved during the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb50f3d-f9db-4fa8-b395-b9c5337dbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d78281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plot_metric_curves(epochs, loss, val_loss, \"darkcyan\", \"turquoise\", \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy curves\n",
    "plot_metric_curves(epochs, acc, val_acc, \"darkcyan\", \"turquoise\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91d735f4-0de1-4d11-9761-bb812d5cbcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=40,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a15d3d-33f0-4f65-871d-bb7048c39494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3f158-c176-4111-b66e-45918c845472",
   "metadata": {
    "id": "pQg4z_l8Tbj9"
   },
   "source": [
    "*Comments about how those metrics have evolved...*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2754bdc1",
   "metadata": {},
   "source": [
    "# **5.2 MobileNetV3 training classifier and last convolutional layer**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c999cbf2",
   "metadata": {},
   "source": [
    "## 5.2.1. Model structure\n",
    "\n",
    "Let's first create the model structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb72ef9",
   "metadata": {},
   "source": [
    "Firstly, let's define the values of some hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a84cdd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 125\n"
     ]
    }
   ],
   "source": [
    "# Define some hyperparameters' values\n",
    "\n",
    "# Input shape\n",
    "input_shape = (224, 224,  3)\n",
    "\n",
    "# Batch_size and steps per epoch\n",
    "training_size = sum([len(file) for path, folder, file in os.walk(train_dir)])\n",
    "batch_size = 128\n",
    "steps_per_epoch = training_size // batch_size\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96170a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_17 (Rescaling)       (None, 224, 224, 3)  0           ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " Conv (Conv2D)                  (None, 112, 112, 16  432         ['rescaling_17[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNormaliza  (None, 112, 112, 16  64         ['Conv[0][0]']                   \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_467 (TFOp  (None, 112, 112, 16  0          ['Conv/BatchNorm[0][0]']         \n",
      " Lambda)                        )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_582 (ReLU)               (None, 112, 112, 16  0           ['tf.__operators__.add_467[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_467 (TFOpLamb  (None, 112, 112, 16  0          ['re_lu_582[0][0]']              \n",
      " da)                            )                                                                 \n",
      "                                                                                                  \n",
      " multiply_319 (Multiply)        (None, 112, 112, 16  0           ['Conv/BatchNorm[0][0]',         \n",
      "                                )                                 'tf.math.multiply_467[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pad (Z  (None, 113, 113, 16  0          ['multiply_319[0][0]']           \n",
      " eroPadding2D)                  )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (Depth  (None, 56, 56, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
      " wiseConv2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/BatchN  (None, 56, 56, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " re_lu_583 (ReLU)               (None, 56, 56, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_583[0][0]']              \n",
      " vgPool (GlobalAveragePooling2D                                                                   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n",
      " onv (Conv2D)                                                    gPool[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n",
      " elu (ReLU)                                                      nv[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n",
      " onv_1 (Conv2D)                                                  lu[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_468 (TFOp  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n",
      " Lambda)                                                         nv_1[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_584 (ReLU)               (None, 1, 1, 16)     0           ['tf.__operators__.add_468[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_468 (TFOpLamb  (None, 1, 1, 16)    0           ['re_lu_584[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/M  (None, 56, 56, 16)  0           ['re_lu_583[0][0]',              \n",
      " ul (Multiply)                                                    'tf.math.multiply_468[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv/project (Conv2D)  (None, 56, 56, 16)  256         ['expanded_conv/squeeze_excite/Mu\n",
      "                                                                 l[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv/project/BatchNor  (None, 56, 56, 16)  64          ['expanded_conv/project[0][0]']  \n",
      " m (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Conv2D  (None, 56, 56, 72)  1152        ['expanded_conv/project/BatchNorm\n",
      " )                                                               [0][0]']                         \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/BatchNo  (None, 56, 56, 72)  288         ['expanded_conv_1/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_585 (ReLU)               (None, 56, 56, 72)   0           ['expanded_conv_1/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/pad   (None, 57, 57, 72)  0           ['re_lu_585[0][0]']              \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise (Dep  (None, 28, 28, 72)  648         ['expanded_conv_1/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/Batc  (None, 28, 28, 72)  288         ['expanded_conv_1/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_586 (ReLU)               (None, 28, 28, 72)   0           ['expanded_conv_1/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (Conv2  (None, 28, 28, 24)  1728        ['re_lu_586[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_1/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Conv2D  (None, 28, 28, 88)  2112        ['expanded_conv_1/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/BatchNo  (None, 28, 28, 88)  352         ['expanded_conv_2/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_587 (ReLU)               (None, 28, 28, 88)   0           ['expanded_conv_2/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise (Dep  (None, 28, 28, 88)  792         ['re_lu_587[0][0]']              \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/Batc  (None, 28, 28, 88)  352         ['expanded_conv_2/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_588 (ReLU)               (None, 28, 28, 88)   0           ['expanded_conv_2/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (Conv2  (None, 28, 28, 24)  2112        ['re_lu_588[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_2/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)      (None, 28, 28, 24)   0           ['expanded_conv_1/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_2/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Conv2D  (None, 28, 28, 96)  2304        ['expanded_conv_2/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/BatchNo  (None, 28, 28, 96)  384         ['expanded_conv_3/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_469 (TFOp  (None, 28, 28, 96)  0           ['expanded_conv_3/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_589 (ReLU)               (None, 28, 28, 96)   0           ['tf.__operators__.add_469[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_469 (TFOpLamb  (None, 28, 28, 96)  0           ['re_lu_589[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_320 (Multiply)        (None, 28, 28, 96)   0           ['expanded_conv_3/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_469[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/pad   (None, 31, 31, 96)  0           ['multiply_320[0][0]']           \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise (Dep  (None, 14, 14, 96)  2400        ['expanded_conv_3/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/Batc  (None, 14, 14, 96)  384         ['expanded_conv_3/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_470 (TFOp  (None, 14, 14, 96)  0           ['expanded_conv_3/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_590 (ReLU)               (None, 14, 14, 96)   0           ['tf.__operators__.add_470[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_470 (TFOpLamb  (None, 14, 14, 96)  0           ['re_lu_590[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_321 (Multiply)        (None, 14, 14, 96)   0           ['expanded_conv_3/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_470[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_321[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_3/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_3/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_3/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_471 (TFOp  (None, 1, 1, 96)    0           ['expanded_conv_3/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_591 (ReLU)               (None, 1, 1, 96)     0           ['tf.__operators__.add_471[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_471 (TFOpLamb  (None, 1, 1, 96)    0           ['re_lu_591[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 14, 14, 96)  0           ['multiply_321[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_471[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (Conv2  (None, 14, 14, 40)  3840        ['expanded_conv_3/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_3/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_3/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_4/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_472 (TFOp  (None, 14, 14, 240)  0          ['expanded_conv_4/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_592 (ReLU)               (None, 14, 14, 240)  0           ['tf.__operators__.add_472[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_472 (TFOpLamb  (None, 14, 14, 240)  0          ['re_lu_592[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_322 (Multiply)        (None, 14, 14, 240)  0           ['expanded_conv_4/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_472[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_322[0][0]']           \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_4/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_473 (TFOp  (None, 14, 14, 240)  0          ['expanded_conv_4/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_593 (ReLU)               (None, 14, 14, 240)  0           ['tf.__operators__.add_473[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_473 (TFOpLamb  (None, 14, 14, 240)  0          ['re_lu_593[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_323 (Multiply)        (None, 14, 14, 240)  0           ['expanded_conv_4/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_473[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_323[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_4/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_4/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_4/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_474 (TFOp  (None, 1, 1, 240)   0           ['expanded_conv_4/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_594 (ReLU)               (None, 1, 1, 240)    0           ['tf.__operators__.add_474[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_474 (TFOpLamb  (None, 1, 1, 240)   0           ['re_lu_594[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_323[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_474[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_4/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_4/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_4/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_3/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_4/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_4/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_5/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_475 (TFOp  (None, 14, 14, 240)  0          ['expanded_conv_5/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_595 (ReLU)               (None, 14, 14, 240)  0           ['tf.__operators__.add_475[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_475 (TFOpLamb  (None, 14, 14, 240)  0          ['re_lu_595[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_324 (Multiply)        (None, 14, 14, 240)  0           ['expanded_conv_5/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_475[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_324[0][0]']           \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_5/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_476 (TFOp  (None, 14, 14, 240)  0          ['expanded_conv_5/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_596 (ReLU)               (None, 14, 14, 240)  0           ['tf.__operators__.add_476[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_476 (TFOpLamb  (None, 14, 14, 240)  0          ['re_lu_596[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_325 (Multiply)        (None, 14, 14, 240)  0           ['expanded_conv_5/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_476[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_325[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_5/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_5/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_5/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_477 (TFOp  (None, 1, 1, 240)   0           ['expanded_conv_5/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_597 (ReLU)               (None, 1, 1, 240)    0           ['tf.__operators__.add_477[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_477 (TFOpLamb  (None, 1, 1, 240)   0           ['re_lu_597[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_325[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_477[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_5/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_5/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_4/Add[0][0]',    \n",
      "                                                                  'expanded_conv_5/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Conv2D  (None, 14, 14, 120)  4800       ['expanded_conv_5/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/BatchNo  (None, 14, 14, 120)  480        ['expanded_conv_6/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_478 (TFOp  (None, 14, 14, 120)  0          ['expanded_conv_6/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_598 (ReLU)               (None, 14, 14, 120)  0           ['tf.__operators__.add_478[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_478 (TFOpLamb  (None, 14, 14, 120)  0          ['re_lu_598[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_326 (Multiply)        (None, 14, 14, 120)  0           ['expanded_conv_6/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_478[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise (Dep  (None, 14, 14, 120)  3000       ['multiply_326[0][0]']           \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/Batc  (None, 14, 14, 120)  480        ['expanded_conv_6/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_479 (TFOp  (None, 14, 14, 120)  0          ['expanded_conv_6/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_599 (ReLU)               (None, 14, 14, 120)  0           ['tf.__operators__.add_479[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_479 (TFOpLamb  (None, 14, 14, 120)  0          ['re_lu_599[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_327 (Multiply)        (None, 14, 14, 120)  0           ['expanded_conv_6/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_479[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   0           ['multiply_327[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    3872        ['expanded_conv_6/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    0           ['expanded_conv_6/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   3960        ['expanded_conv_6/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_480 (TFOp  (None, 1, 1, 120)   0           ['expanded_conv_6/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_600 (ReLU)               (None, 1, 1, 120)    0           ['tf.__operators__.add_480[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_480 (TFOpLamb  (None, 1, 1, 120)   0           ['re_lu_600[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 14, 14, 120)  0          ['multiply_327[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_480[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (Conv2  (None, 14, 14, 48)  5760        ['expanded_conv_6/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_6/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand (Conv2D  (None, 14, 14, 144)  6912       ['expanded_conv_6/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/BatchNo  (None, 14, 14, 144)  576        ['expanded_conv_7/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_481 (TFOp  (None, 14, 14, 144)  0          ['expanded_conv_7/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_601 (ReLU)               (None, 14, 14, 144)  0           ['tf.__operators__.add_481[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_481 (TFOpLamb  (None, 14, 14, 144)  0          ['re_lu_601[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_328 (Multiply)        (None, 14, 14, 144)  0           ['expanded_conv_7/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_481[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise (Dep  (None, 14, 14, 144)  3600       ['multiply_328[0][0]']           \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/Batc  (None, 14, 14, 144)  576        ['expanded_conv_7/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_482 (TFOp  (None, 14, 14, 144)  0          ['expanded_conv_7/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_602 (ReLU)               (None, 14, 14, 144)  0           ['tf.__operators__.add_482[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_482 (TFOpLamb  (None, 14, 14, 144)  0          ['re_lu_602[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_329 (Multiply)        (None, 14, 14, 144)  0           ['expanded_conv_7/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_482[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   0           ['multiply_329[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    5800        ['expanded_conv_7/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    0           ['expanded_conv_7/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   5904        ['expanded_conv_7/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_483 (TFOp  (None, 1, 1, 144)   0           ['expanded_conv_7/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_603 (ReLU)               (None, 1, 1, 144)    0           ['tf.__operators__.add_483[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_483 (TFOpLamb  (None, 1, 1, 144)   0           ['re_lu_603[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 14, 14, 144)  0          ['multiply_329[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_483[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (Conv2  (None, 14, 14, 48)  6912        ['expanded_conv_7/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_7/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)      (None, 14, 14, 48)   0           ['expanded_conv_6/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_7/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Conv2D  (None, 14, 14, 288)  13824      ['expanded_conv_7/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/BatchNo  (None, 14, 14, 288)  1152       ['expanded_conv_8/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_484 (TFOp  (None, 14, 14, 288)  0          ['expanded_conv_8/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_604 (ReLU)               (None, 14, 14, 288)  0           ['tf.__operators__.add_484[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_484 (TFOpLamb  (None, 14, 14, 288)  0          ['re_lu_604[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_330 (Multiply)        (None, 14, 14, 288)  0           ['expanded_conv_8/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_484[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/pad   (None, 17, 17, 288)  0          ['multiply_330[0][0]']           \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise (Dep  (None, 7, 7, 288)   7200        ['expanded_conv_8/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/Batc  (None, 7, 7, 288)   1152        ['expanded_conv_8/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_485 (TFOp  (None, 7, 7, 288)   0           ['expanded_conv_8/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_605 (ReLU)               (None, 7, 7, 288)    0           ['tf.__operators__.add_485[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_485 (TFOpLamb  (None, 7, 7, 288)   0           ['re_lu_605[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_331 (Multiply)        (None, 7, 7, 288)    0           ['expanded_conv_8/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_485[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   0           ['multiply_331[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    20808       ['expanded_conv_8/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    0           ['expanded_conv_8/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   21024       ['expanded_conv_8/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_486 (TFOp  (None, 1, 1, 288)   0           ['expanded_conv_8/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_606 (ReLU)               (None, 1, 1, 288)    0           ['tf.__operators__.add_486[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_486 (TFOpLamb  (None, 1, 1, 288)   0           ['re_lu_606[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 7, 7, 288)   0           ['multiply_331[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_486[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (Conv2  (None, 7, 7, 96)    27648       ['expanded_conv_8/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_8/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Conv2D  (None, 7, 7, 576)   55296       ['expanded_conv_8/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/BatchNo  (None, 7, 7, 576)   2304        ['expanded_conv_9/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_487 (TFOp  (None, 7, 7, 576)   0           ['expanded_conv_9/expand/BatchNor\n",
      " Lambda)                                                         m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_607 (ReLU)               (None, 7, 7, 576)    0           ['tf.__operators__.add_487[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_487 (TFOpLamb  (None, 7, 7, 576)   0           ['re_lu_607[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_332 (Multiply)        (None, 7, 7, 576)    0           ['expanded_conv_9/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_487[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise (Dep  (None, 7, 7, 576)   14400       ['multiply_332[0][0]']           \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/Batc  (None, 7, 7, 576)   2304        ['expanded_conv_9/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_488 (TFOp  (None, 7, 7, 576)   0           ['expanded_conv_9/depthwise/Batch\n",
      " Lambda)                                                         Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_608 (ReLU)               (None, 7, 7, 576)    0           ['tf.__operators__.add_488[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_488 (TFOpLamb  (None, 7, 7, 576)   0           ['re_lu_608[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_333 (Multiply)        (None, 7, 7, 576)    0           ['expanded_conv_9/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_488[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   0           ['multiply_333[0][0]']           \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   83088       ['expanded_conv_9/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   0           ['expanded_conv_9/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   83520       ['expanded_conv_9/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_489 (TFOp  (None, 1, 1, 576)   0           ['expanded_conv_9/squeeze_excite/\n",
      " Lambda)                                                         Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_609 (ReLU)               (None, 1, 1, 576)    0           ['tf.__operators__.add_489[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_489 (TFOpLamb  (None, 1, 1, 576)   0           ['re_lu_609[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 7, 7, 576)   0           ['multiply_333[0][0]',           \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_489[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (Conv2  (None, 7, 7, 96)    55296       ['expanded_conv_9/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_9/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)      (None, 7, 7, 96)     0           ['expanded_conv_8/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_9/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (Conv2  (None, 7, 7, 576)   55296       ['expanded_conv_9/Add[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/BatchN  (None, 7, 7, 576)   2304        ['expanded_conv_10/expand[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_490 (TFOp  (None, 7, 7, 576)   0           ['expanded_conv_10/expand/BatchNo\n",
      " Lambda)                                                         rm[0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_610 (ReLU)               (None, 7, 7, 576)    0           ['tf.__operators__.add_490[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_490 (TFOpLamb  (None, 7, 7, 576)   0           ['re_lu_610[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_334 (Multiply)        (None, 7, 7, 576)    0           ['expanded_conv_10/expand/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'tf.math.multiply_490[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise (De  (None, 7, 7, 576)   14400       ['multiply_334[0][0]']           \n",
      " pthwiseConv2D)                                                                                   \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise/Bat  (None, 7, 7, 576)   2304        ['expanded_conv_10/depthwise[0][0\n",
      " chNorm (BatchNormalization)                                     ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_491 (TFOp  (None, 7, 7, 576)   0           ['expanded_conv_10/depthwise/Batc\n",
      " Lambda)                                                         hNorm[0][0]']                    \n",
      "                                                                                                  \n",
      " re_lu_611 (ReLU)               (None, 7, 7, 576)    0           ['tf.__operators__.add_491[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_491 (TFOpLamb  (None, 7, 7, 576)   0           ['re_lu_611[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_335 (Multiply)        (None, 7, 7, 576)    0           ['expanded_conv_10/depthwise/Batc\n",
      "                                                                 hNorm[0][0]',                    \n",
      "                                                                  'tf.math.multiply_491[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   0           ['multiply_335[0][0]']           \n",
      " e/AvgPool (GlobalAveragePoolin                                                                   \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   83088       ['expanded_conv_10/squeeze_excite\n",
      " e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   0           ['expanded_conv_10/squeeze_excite\n",
      " e/Relu (ReLU)                                                   /Conv[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   83520       ['expanded_conv_10/squeeze_excite\n",
      " e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_492 (TFOp  (None, 1, 1, 576)   0           ['expanded_conv_10/squeeze_excite\n",
      " Lambda)                                                         /Conv_1[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_612 (ReLU)               (None, 1, 1, 576)    0           ['tf.__operators__.add_492[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_492 (TFOpLamb  (None, 1, 1, 576)   0           ['re_lu_612[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 7, 7, 576)   0           ['multiply_335[0][0]',           \n",
      " e/Mul (Multiply)                                                 'tf.math.multiply_492[0][0]']   \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (Conv  (None, 7, 7, 96)    55296       ['expanded_conv_10/squeeze_excite\n",
      " 2D)                                                             /Mul[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/Batch  (None, 7, 7, 96)    384         ['expanded_conv_10/project[0][0]'\n",
      " Norm (BatchNormalization)                                       ]                                \n",
      "                                                                                                  \n",
      " expanded_conv_10/Add (Add)     (None, 7, 7, 96)     0           ['expanded_conv_9/Add[0][0]',    \n",
      "                                                                  'expanded_conv_10/project/BatchN\n",
      "                                                                 orm[0][0]']                      \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 576)    55296       ['expanded_conv_10/Add[0][0]']   \n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNormali  (None, 7, 7, 576)   2304        ['Conv_1[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_493 (TFOp  (None, 7, 7, 576)   0           ['Conv_1/BatchNorm[0][0]']       \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_613 (ReLU)               (None, 7, 7, 576)    0           ['tf.__operators__.add_493[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_493 (TFOpLamb  (None, 7, 7, 576)   0           ['re_lu_613[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply_336 (Multiply)        (None, 7, 7, 576)    0           ['Conv_1/BatchNorm[0][0]',       \n",
      "                                                                  'tf.math.multiply_493[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 939,120\n",
      "Trainable params: 927,008\n",
      "Non-trainable params: 12,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# conv_base = MobileNetV3Large( \n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_shape=input_shape,\n",
    "#     alpha=1.0,\n",
    "#     pooling=None,\n",
    "#     dropout_rate=0.2,\n",
    "# )\n",
    "\n",
    "conv_base = MobileNetV3Small( \n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91ec3aba-8d04-46be-a192-08a36a44f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the convolutional base unless the last layer\n",
    "conv_base.trainable = True\n",
    "\n",
    "# Unfreeze the last layer\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'Conv_1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the convolutional base\n",
    "model.add(conv_base)\n",
    "\n",
    "# Add the classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62728440",
   "metadata": {},
   "source": [
    "Once the structure of the base model has been defined, let's see exactly how many parameters it has in order to have a better idea of how flexible this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17ce1ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 28224)             0         \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 28224)            112896    \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 128)               3612800   \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,673,844\n",
      "Trainable params: 3,734,468\n",
      "Non-trainable params: 939,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f8f58",
   "metadata": {},
   "source": [
    "We'll use Adam as our optimizer since it is the most popular optimizer right now, as well as versatile (i.e., it can be used in multiple contexts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaac944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c7c98ea",
   "metadata": {},
   "source": [
    "## 5.2.2. Data preprocessing\n",
    "\n",
    "In this case, we will include the Data Augmentation step to the model preprocessing step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "494bb0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 4 classes.\n",
      "Found 2000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Apply data augmentation to the training set\n",
    "# https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.8, 1),\n",
    "    zoom_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "# The data augmentation must not be used for the test set!\n",
    "# All images will be rescaled by 1./255\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        # All images will be resized to the dimensions specified\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        # All images will be resized to the dimensions specified\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd67e04",
   "metadata": {},
   "source": [
    "Now let's take a look at the output of one of these generators (for instance, the training one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4bc9a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: (128, 224, 224, 3)\n",
      "Labels batch shape: (128, 4)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data batch shape:', data_batch.shape)\n",
    "    print('Labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95060855",
   "metadata": {},
   "source": [
    "*We can appreciate that...*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "345e8a98",
   "metadata": {},
   "source": [
    "## 5.2.3. Training\n",
    "\n",
    "Let's train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8a972",
   "metadata": {},
   "source": [
    "We use [Early Stopping](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) to avoid *overfitting*, as well `ModelCheckpoint` to save the best model obtained during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd2bfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name and path\n",
    "model_path = os.path.join(\"models\", \"mobilenet_unfrozen_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9d682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(model_path, monitor='val_loss', \n",
    "                     mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b77f450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 39/125 [========>.....................] - ETA: 6:55 - loss: 1.5509 - acc: 0.3355"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     train_generator,\n\u001b[0;32m      3\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      6\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m     callbacks \u001b[39m=\u001b[39;49m [es, mc]\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10,\n",
    "    callbacks = [es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431782a",
   "metadata": {},
   "source": [
    "Now let's load the best model found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "saved_model = load_model(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b2063ec",
   "metadata": {},
   "source": [
    "## 5.2.4. Validation\n",
    "\n",
    "Let's plot how the loss and the accuracy from both training and validations sets have evolved during the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71466e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plot_metric_curves(epochs, loss, val_loss, \"darkcyan\", \"turquoise\", \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy curves\n",
    "plot_metric_curves(epochs, acc, val_acc, \"darkcyan\", \"turquoise\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71095d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=40,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95341484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade4289",
   "metadata": {},
   "source": [
    "*Comments about how those metrics have evolved...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
